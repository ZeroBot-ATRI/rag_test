"""
RAG (æ£€ç´¢å¢å¼ºç”Ÿæˆ) ç³»ç»Ÿ
åŠŸèƒ½ï¼š
1. ä»å‘é‡æ•°æ®åº“æ£€ç´¢ç›¸å…³çŸ¥è¯†
2. ä½¿ç”¨LLMç”Ÿæˆé«˜è´¨é‡å›ç­”
3. æä¾›å®Œæ•´çš„é—®ç­”ä½“éªŒ
"""

from sentence_transformers import SentenceTransformer
from milvus_client import MyMilvusClient
from openai import OpenAI
import config
import sys

class PromptTemplate:
    """æç¤ºè¯æ¨¡æ¿ç®¡ç†å™¨"""
    
    # ç³»ç»Ÿæç¤ºè¯
    SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¼–ç¨‹å­¦ä¹ åŠ©æ‰‹ï¼Œä¸“æ³¨äºPythonå’ŒJAVAæŠ€æœ¯é—®ç­”ã€‚
ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®æä¾›çš„çŸ¥è¯†åº“å†…å®¹ï¼Œä¸ºç”¨æˆ·æä¾›å‡†ç¡®ã€è¯¦ç»†ã€æ˜“æ‡‚çš„æŠ€æœ¯è§£ç­”ã€‚

å›ç­”è¦æ±‚ï¼š
1. åŸºäºæä¾›çš„å‚è€ƒèµ„æ–™å›ç­”é—®é¢˜ï¼Œä¿æŒå‡†ç¡®æ€§
2. å¦‚æœå‚è€ƒèµ„æ–™ä¸­æœ‰ä»£ç ç¤ºä¾‹ï¼Œè¯·å®Œæ•´å±•ç¤º
3. ç”¨æ¸…æ™°çš„è¯­è¨€è§£é‡ŠæŠ€æœ¯æ¦‚å¿µ
4. å¦‚æœå‚è€ƒèµ„æ–™ä¸å¤Ÿå……åˆ†ï¼Œå¯ä»¥é€‚å½“è¡¥å……ä½ çš„çŸ¥è¯†ï¼Œä½†è¦æ˜ç¡®è¯´æ˜
5. ä¿æŒä¸“ä¸šã€å‹å¥½çš„è¯­æ°”
6. ä½¿ç”¨Markdownæ ¼å¼ç»„ç»‡ç­”æ¡ˆï¼Œæå‡å¯è¯»æ€§
"""

    # ç”¨æˆ·é—®é¢˜æ¨¡æ¿
    USER_PROMPT_TEMPLATE = """ç”¨æˆ·é—®é¢˜ï¼š{question}

å‚è€ƒèµ„æ–™ï¼ˆæ¥è‡ªçŸ¥è¯†åº“ï¼‰ï¼š
{context}

è¯·åŸºäºä»¥ä¸Šå‚è€ƒèµ„æ–™å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚å¦‚æœå‚è€ƒèµ„æ–™å·²ç»åŒ…å«å®Œæ•´ç­”æ¡ˆï¼Œè¯·ç›´æ¥ä½¿ç”¨ï¼›å¦‚æœéœ€è¦è¡¥å……è¯´æ˜ï¼Œè¯·åœ¨ä¿æŒå‡†ç¡®æ€§çš„å‰æä¸‹é€‚å½“å±•å¼€ã€‚
"""

    # æ— å‚è€ƒèµ„æ–™æ—¶çš„æ¨¡æ¿
    NO_CONTEXT_PROMPT = """ç”¨æˆ·é—®é¢˜ï¼š{question}

çŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°ç›´æ¥ç›¸å…³çš„å‚è€ƒèµ„æ–™ã€‚

è¯·åŸºäºä½ çš„ä¸“ä¸šçŸ¥è¯†å›ç­”è¿™ä¸ªé—®é¢˜ï¼Œå¹¶åœ¨å›ç­”å¼€å¤´è¯´æ˜"çŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°ç›´æ¥ç›¸å…³çš„å†…å®¹ï¼Œä»¥ä¸‹æ˜¯åŸºäºé€šç”¨çŸ¥è¯†çš„å›ç­”"ã€‚
"""

    @classmethod
    def format_context(cls, search_results, max_results=3):
        """
        æ ¼å¼åŒ–æ£€ç´¢ç»“æœä¸ºä¸Šä¸‹æ–‡
        :param search_results: æ£€ç´¢ç»“æœ
        :param max_results: æœ€å¤šä½¿ç”¨çš„ç»“æœæ•°é‡
        :return: æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        """
        if not search_results or len(search_results) == 0:
            return None
        
        context_parts = []
        for idx, result in enumerate(search_results[:max_results], 1):
            subject = result.get('subject', 'N/A')
            question = result.get('question', 'N/A')
            answer = result.get('answer', 'N/A')
            distance = result.get('distance', 0)
            
            context_parts.append(f"""
ã€å‚è€ƒèµ„æ–™ {idx}ã€‘(ç›¸ä¼¼åº¦: {1-distance:.2%})
å­¦ç§‘ï¼š{subject}
é—®é¢˜ï¼š{question}
ç­”æ¡ˆï¼š{answer}
""")
        
        return "\n".join(context_parts)
    
    @classmethod
    def create_messages(cls, question, context=None):
        """
        åˆ›å»ºå¯¹è¯æ¶ˆæ¯åˆ—è¡¨
        :param question: ç”¨æˆ·é—®é¢˜
        :param context: æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡
        :return: æ¶ˆæ¯åˆ—è¡¨
        """
        messages = [
            {"role": "system", "content": cls.SYSTEM_PROMPT}
        ]
        
        if context:
            user_content = cls.USER_PROMPT_TEMPLATE.format(
                question=question,
                context=context
            )
        else:
            user_content = cls.NO_CONTEXT_PROMPT.format(question=question)
        
        messages.append({"role": "user", "content": user_content})
        
        return messages


class RAGSystem:
    """RAGç³»ç»Ÿä¸»ç±»"""
    
    def __init__(self, db_name='test1016', collection_name='jp_knowledge_qa'):
        """åˆå§‹åŒ–RAGç³»ç»Ÿ"""
        print("æ­£åœ¨åˆå§‹åŒ–RAGç³»ç»Ÿ...")
        
        # åˆå§‹åŒ–å‘é‡æ•°æ®åº“
        print("1. è¿æ¥å‘é‡æ•°æ®åº“...")
        self.db_name = db_name
        self.collection_name = collection_name
        self.client = MyMilvusClient(db_name=db_name)
        
        # åŠ è½½Embeddingæ¨¡å‹
        print("2. åŠ è½½Embeddingæ¨¡å‹...")
        self.model = SentenceTransformer("Qwen/Qwen3-Embedding-0.6B")
        
        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        print("3. åˆå§‹åŒ–LLMå®¢æˆ·ç«¯...")
        self.llm_client = OpenAI(
            api_key=config.API_KEY,
            base_url=config.BASE_URL
        )
        self.llm_model = config.MODEL
        
        print("âœ“ RAGç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼\n")
    
    def retrieve(self, query, top_k=3, subject_filter=None, similarity_threshold=0.7):
        """
        ä»å‘é‡æ•°æ®åº“æ£€ç´¢ç›¸å…³çŸ¥è¯†
        :param query: æŸ¥è¯¢é—®é¢˜
        :param top_k: è¿”å›top kä¸ªç»“æœ
        :param subject_filter: å­¦ç§‘è¿‡æ»¤
        :param similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆè·ç¦»è¶Šå°è¶Šç›¸ä¼¼ï¼Œè¿™é‡Œæ˜¯æœ€å¤§è·ç¦»ï¼‰
        :return: æ£€ç´¢ç»“æœåˆ—è¡¨
        """
        # ç”ŸæˆæŸ¥è¯¢å‘é‡
        query_embedding = self.model.encode([query], prompt_name="query")[0]
        
        # æ‰§è¡Œæœç´¢
        search_results = self.client.search(
            collection_name=self.collection_name,
            data=[query_embedding.tolist()],
            limit=top_k * 2 if subject_filter else top_k,
            output_fields=["id", "subject", "question", "answer"]
        )
        
        # å¤„ç†ç»“æœ
        results = []
        for hits in search_results:
            for hit in hits:
                # è¿‡æ»¤å­¦ç§‘
                if subject_filter and hit.get('subject') != subject_filter:
                    continue
                
                # è¿‡æ»¤ç›¸ä¼¼åº¦
                distance = hit.get('distance', 1.0)
                if distance > similarity_threshold:
                    continue
                
                results.append(hit)
                
                if len(results) >= top_k:
                    break
            
            if len(results) >= top_k:
                break
        
        return results
    
    def generate(self, messages, stream=False, temperature=0.7, max_tokens=2000):
        """
        ä½¿ç”¨LLMç”Ÿæˆå›ç­”
        :param messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨
        :param stream: æ˜¯å¦æµå¼è¾“å‡º
        :param temperature: æ¸©åº¦å‚æ•°ï¼ˆ0-1ï¼Œè¶Šé«˜è¶Šéšæœºï¼‰
        :param max_tokens: æœ€å¤§tokenæ•°
        :return: ç”Ÿæˆçš„å›ç­”
        """
        try:
            response = self.llm_client.chat.completions.create(
                model=self.llm_model,
                messages=messages,
                stream=stream,
                temperature=temperature,
                max_tokens=max_tokens
            )
            
            if stream:
                return response  # è¿”å›æµå¼å“åº”å¯¹è±¡
            else:
                return response.choices[0].message.content
                
        except Exception as e:
            return f"LLMè°ƒç”¨å¤±è´¥: {e}"
    
    def answer(self, question, subject_filter=None, top_k=3, 
               stream=False, show_context=True, temperature=0.7):
        """
        å®Œæ•´çš„RAGé—®ç­”æµç¨‹
        :param question: ç”¨æˆ·é—®é¢˜
        :param subject_filter: å­¦ç§‘è¿‡æ»¤
        :param top_k: æ£€ç´¢ç»“æœæ•°é‡
        :param stream: æ˜¯å¦æµå¼è¾“å‡º
        :param show_context: æ˜¯å¦æ˜¾ç¤ºæ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡
        :param temperature: LLMæ¸©åº¦å‚æ•°
        :return: å›ç­”å†…å®¹
        """
        print("=" * 80)
        print(f"é—®é¢˜ï¼š{question}")
        if subject_filter:
            print(f"é™å®šå­¦ç§‘ï¼š{subject_filter}")
        print("=" * 80)
        
        # 1. æ£€ç´¢ç›¸å…³çŸ¥è¯†
        print("\n[1/3] æ­£åœ¨æ£€ç´¢ç›¸å…³çŸ¥è¯†...")
        results = self.retrieve(question, top_k=top_k, subject_filter=subject_filter)
        
        if results:
            print(f"âœ“ æ‰¾åˆ° {len(results)} æ¡ç›¸å…³å‚è€ƒèµ„æ–™")
        else:
            print("âœ— æœªæ‰¾åˆ°ç›¸å…³å‚è€ƒèµ„æ–™ï¼Œå°†ä½¿ç”¨LLMé€šç”¨çŸ¥è¯†å›ç­”")
        
        # 2. æ ¼å¼åŒ–ä¸Šä¸‹æ–‡
        context = PromptTemplate.format_context(results, max_results=top_k)
        
        # æ˜¾ç¤ºæ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡
        if show_context and context:
            print("\n" + "-" * 80)
            print("æ£€ç´¢åˆ°çš„å‚è€ƒèµ„æ–™ï¼š")
            print("-" * 80)
            for idx, result in enumerate(results[:top_k], 1):
                print(f"\nã€{idx}ã€‘ç›¸ä¼¼åº¦: {1-result.get('distance', 1):.2%}")
                print(f"å­¦ç§‘ï¼š{result.get('subject', 'N/A')}")
                print(f"é—®é¢˜ï¼š{result.get('question', 'N/A')[:80]}...")
            print("-" * 80)
        
        # 3. ç”Ÿæˆå›ç­”
        print("\n[2/3] æ­£åœ¨ç”Ÿæˆå›ç­”...")
        messages = PromptTemplate.create_messages(question, context)
        
        print("\n[3/3] å›ç­”å†…å®¹ï¼š")
        print("=" * 80)
        
        if stream:
            # æµå¼è¾“å‡º
            response_stream = self.generate(messages, stream=True, temperature=temperature)
            full_response = ""
            try:
                for chunk in response_stream:
                    if chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        print(content, end='', flush=True)
                        full_response += content
                print()  # æ¢è¡Œ
            except Exception as e:
                print(f"\næµå¼è¾“å‡ºé”™è¯¯: {e}")
                return None
            return full_response
        else:
            # éæµå¼è¾“å‡º
            answer = self.generate(messages, stream=False, temperature=temperature)
            print(answer)
            print("=" * 80)
            return answer
    
    def chat(self):
        """äº¤äº’å¼èŠå¤©æ¨¡å¼"""
        print("\n" + "=" * 80)
        print("RAG æ™ºèƒ½é—®ç­”ç³»ç»Ÿ - äº¤äº’æ¨¡å¼")
        print("=" * 80)
        print("\nä½¿ç”¨è¯´æ˜ï¼š")
        print("  - ç›´æ¥è¾“å…¥é—®é¢˜è¿›è¡Œæé—®")
        print("  - è¾“å…¥ '/python' æˆ– '/java' é™å®šå­¦ç§‘")
        print("  - è¾“å…¥ '/stream' åˆ‡æ¢æµå¼/éæµå¼è¾“å‡º")
        print("  - è¾“å…¥ '/context' åˆ‡æ¢æ˜¯å¦æ˜¾ç¤ºå‚è€ƒèµ„æ–™")
        print("  - è¾“å…¥ '/clear' æ¸…ç©ºå­¦ç§‘é™å®š")
        print("  - è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º")
        print("=" * 80 + "\n")
        
        subject_filter = None
        stream_mode = True
        show_context = True
        
        while True:
            try:
                user_input = input("\nğŸ’¬ æ‚¨çš„é—®é¢˜: ").strip()
                
                if not user_input:
                    continue
                
                # å¤„ç†å‘½ä»¤
                if user_input.lower() in ['quit', 'exit', 'q', 'é€€å‡º']:
                    print("\næ„Ÿè°¢ä½¿ç”¨ï¼å†è§ï¼ğŸ‘‹")
                    break
                
                if user_input.lower() == '/python':
                    subject_filter = "Pythonå­¦ç§‘"
                    print(f"âœ“ å·²é™å®šå­¦ç§‘ï¼š{subject_filter}")
                    continue
                
                if user_input.lower() == '/java':
                    subject_filter = "JAVAå­¦ç§‘"
                    print(f"âœ“ å·²é™å®šå­¦ç§‘ï¼š{subject_filter}")
                    continue
                
                if user_input.lower() == '/clear':
                    subject_filter = None
                    print("âœ“ å·²æ¸…é™¤å­¦ç§‘é™å®š")
                    continue
                
                if user_input.lower() == '/stream':
                    stream_mode = not stream_mode
                    print(f"âœ“ æµå¼è¾“å‡ºï¼š{'å¼€å¯' if stream_mode else 'å…³é—­'}")
                    continue
                
                if user_input.lower() == '/context':
                    show_context = not show_context
                    print(f"âœ“ æ˜¾ç¤ºå‚è€ƒèµ„æ–™ï¼š{'å¼€å¯' if show_context else 'å…³é—­'}")
                    continue
                
                # æ‰§è¡Œé—®ç­”
                self.answer(
                    question=user_input,
                    subject_filter=subject_filter,
                    top_k=3,
                    stream=stream_mode,
                    show_context=show_context,
                    temperature=0.7
                )
                
            except KeyboardInterrupt:
                print("\n\næ„Ÿè°¢ä½¿ç”¨ï¼å†è§ï¼ğŸ‘‹")
                break
            except Exception as e:
                print(f"\nâŒ é”™è¯¯: {e}")
                import traceback
                traceback.print_exc()


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "=" * 80)
    print("RAG æ™ºèƒ½é—®ç­”ç³»ç»Ÿ")
    print("=" * 80 + "\n")
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    rag = RAGSystem()
    
    # ç¤ºä¾‹é—®ç­”
    print("\n" + "=" * 80)
    print("ç¤ºä¾‹é—®ç­”")
    print("=" * 80 + "\n")
    
    # ç¤ºä¾‹1ï¼šPythonè£…é¥°å™¨
    rag.answer(
        question="å¦‚ä½•ä½¿ç”¨è£…é¥°å™¨è®¡ç®—å‡½æ•°è¿è¡Œæ—¶é—´ï¼Ÿ",
        top_k=2,
        stream=False,
        show_context=True
    )
    
    print("\n" + "=" * 80 + "\n")
    
    # è¯¢é—®æ˜¯å¦è¿›å…¥äº¤äº’æ¨¡å¼
    choice = input("æ˜¯å¦è¿›å…¥äº¤äº’æ¨¡å¼ï¼Ÿ(y/n): ").strip().lower()
    if choice in ['y', 'yes', 'æ˜¯']:
        rag.chat()
    else:
        print("\næ„Ÿè°¢ä½¿ç”¨ï¼")


if __name__ == "__main__":
    main()
